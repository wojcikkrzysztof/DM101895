{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # obliczenia\n",
    "import numpy as np # obliczenia\n",
    "import matplotlib.pyplot as plt # grafika\n",
    "import seaborn as sns # grafika\n",
    "import csv\n",
    "import re\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions\n",
    "def impute_emb(cols):\n",
    "\n",
    "    if pd.isnull(cols):\n",
    "        return 1\n",
    "    else:\n",
    "        if cols == 'S':\n",
    "            return 1\n",
    "        elif cols == 'C':\n",
    "            return 2\n",
    "        elif cols == 'Q':\n",
    "            return 3\n",
    "\n",
    "def impute_sex(cols):\n",
    "    if cols == 'male':\n",
    "        return 1\n",
    "    elif cols == 'female':\n",
    "        return 0\n",
    "\n",
    "# Function based on results of correlation:\n",
    "# train['Age'].corr(train['Pclass']) <- max cor\n",
    "# train['Age'].corr(train['Fare'])\n",
    "# train['Age'].corr(train['Parch'])\n",
    "# train['Age'].corr(train['SibSp']) <- 2nd max cor\n",
    "# train['Age'].corr(train['Embarked'])\n",
    "# train[['Age','Pclass','SibSp']].groupby(['Pclass','SibSp']).median()\n",
    "# With the results in mind I decided to calculate age based on 2 most correlated factors 'Pclass' and 'SibSp'\n",
    "def impute_age(cols):\n",
    "    Age = cols[0]\n",
    "    Pclass = cols[1]\n",
    "    sibsp = cols[2]\n",
    "\n",
    "    if pd.isnull(Age):\n",
    "\n",
    "        if Pclass == 1:\n",
    "            if sibsp == 0:\n",
    "                return 37\n",
    "            elif sibsp == 1:\n",
    "                return 38\n",
    "            elif sibsp == 2:\n",
    "                return 44\n",
    "            else:\n",
    "                return 23\n",
    "        elif Pclass == 2:\n",
    "            if sibsp == 0:\n",
    "                return 30\n",
    "            elif sibsp == 1:\n",
    "                return 29\n",
    "            elif sibsp == 2:\n",
    "                return 24\n",
    "            else:\n",
    "                return 30\n",
    "        else:\n",
    "            if sibsp == 0:\n",
    "                return 26\n",
    "            elif sibsp == 1:\n",
    "                return 25\n",
    "            elif sibsp == 2:\n",
    "                return 20\n",
    "            elif sibsp == 3:\n",
    "                return 6\n",
    "            elif sibsp == 4:\n",
    "                return 7\n",
    "            else:\n",
    "                return 11\n",
    "\n",
    "    else:\n",
    "        return Age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIAL CLEAN UP\n",
    "# Delete Cabins\n",
    "train.drop('Cabin',axis=1,inplace=True)\n",
    "# As fare/pclass is strongly correlated, I will drop fare\n",
    "train.drop('Fare',axis=1,inplace=True)\n",
    "# I will drop ticket as well, it doesn't seem to mean anything\n",
    "train.drop('Ticket',axis=1,inplace=True)\n",
    "# Drop passengerid, completely useless\n",
    "train.drop('PassengerId',axis=1,inplace=True)\n",
    "# Apply helper functions to Emabarked, Sex\n",
    "train['Embarked'] = train['Embarked'].apply(impute_emb)\n",
    "train['Sex'] = train['Sex'].apply(impute_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AGE clean up\n",
    "# Impute Age\n",
    "train['Age'] = train[['Age','Pclass','SibSp']].apply(impute_age,axis=1)\n",
    "# Convert into age categories\n",
    "train['Age'] = pd.cut(train['Age'], bins=[0,17,64,100],labels=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NAME clean up - extract title from name\n",
    "# Idea and solution taken from https://www.kaggle.com/sinakhorami/titanic-best-working-classifier\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train['Title'] = train['Name'].apply(get_title)\n",
    "\n",
    "train['Title'] = train['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n",
    "train['Title'] = train['Title'].replace('Mlle', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Ms', 'Miss')\n",
    "train['Title'] = train['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# pd.crosstab(train['Title'], train['Sex'])\n",
    "train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()\n",
    "\n",
    "# Mapping\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "train['Title'] = train['Title'].map(title_mapping)\n",
    "train['Title'] = train['Title'].fillna(0)\n",
    "\n",
    "# Drop Name column\n",
    "train.drop('Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into data and target\n",
    "target = train['Survived']\n",
    "train.drop('Survived',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pclass, -0.33848103596101475\n",
      "Sex, -0.543351380657755\n",
      "Age, -0.10426452420931441\n",
      "SibSp, -0.03532249888573559\n",
      "Parch, 0.08162940708348365\n",
      "Embarked, 0.10681138570891938\n",
      "Title, 0.467332589152995\n"
     ]
    }
   ],
   "source": [
    "# Check correlations. Sex, Title and Pclass are the most correlated\n",
    "for col in list(train):\n",
    "    print(\"{}, {}\".format(col, target.corr(train[col])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick classifiers\n",
    "clf4 = RidgeClassifier(tol=1e-4, solver=\"saga\",\n",
    "                               fit_intercept=True, alpha=0.05)\n",
    "clf6 = GradientBoostingClassifier(n_estimators=50, max_features='auto', loss='exponential',max_depth=3)\n",
    "clf8 = ExtraTreesClassifier(n_estimators=10,criterion='entropy')\n",
    "clf13 = LogisticRegression(solver='newton-cg')\n",
    "clf14 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRIDSEARCH classifiers to tune parameters\n",
    "params = {\n",
    "#clf8\n",
    "#     'n_estimators':[3, 5, 10],\n",
    "#     'criterion':['gini','entropy'],\n",
    "#     'max_features':['auto'],\n",
    "#clf6\n",
    "#     'n_estimators':[10,20,30,40,50,60,70],\n",
    "#     'max_features':['auto',None],\n",
    "#     'max_depth':[2,3,4],\n",
    "#     'loss':['deviance','exponential']\n",
    "#clf4\n",
    "#     'tol':[1e-4,1e-5],\n",
    "#     'solver':['saga'],\n",
    "#     'fit_intercept':[True],\n",
    "#     'alpha':[0.05,0.1,0.5]\n",
    "#clf13\n",
    "#     'solver':['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#     'C':[1,2,5],\n",
    "#     'tol':[1e-3,1e-4,1e-5],\n",
    "}\n",
    "clf = GridSearchCV(clf4, param_grid=params, n_jobs=7, verbose=10, cv=10)\n",
    "clf.fit(train, target)\n",
    "print(\"BEST:\")\n",
    "print(clf.best_params_)\n",
    "print(clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make lists for the Voting Classifier\n",
    "list = [\n",
    "    clf14,\n",
    "    clf13,\n",
    "#     clf4,\n",
    "#     clf6,\n",
    "    clf8,\n",
    "]\n",
    "list_names = [\n",
    "    'naive Gaussian',\n",
    "    'logistic',\n",
    "#     'Rigde',\n",
    "#     'GBC',\n",
    "    'ExtraTrees',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    1.7s remaining:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    2.3s remaining:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    2.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:    3.4s remaining:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    3.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    4.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive Gaussian\n",
      "[[481  68]\n",
      " [ 92 250]]\n",
      "0.8204264870931538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    1.7s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    2.3s remaining:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:    3.5s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    4.1s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic\n",
      "[[484  65]\n",
      " [ 92 250]]\n",
      "0.8237934904601572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    1.7s remaining:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    2.2s remaining:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    2.8s remaining:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:    3.3s remaining:    1.9s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    3.9s remaining:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    4.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    4.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTrees\n",
      "[[501  48]\n",
      " [125 217]]\n",
      "0.8058361391694725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    1.8s remaining:    5.6s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    2.4s remaining:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    3.0s remaining:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:    3.6s remaining:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    4.2s remaining:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOTING CLASSIFIER hard\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      alive       0.84      0.90      0.87       549\n",
      "       dead       0.81      0.73      0.77       342\n",
      "\n",
      "avg / total       0.83      0.83      0.83       891\n",
      "\n",
      "[[492  57]\n",
      " [ 91 251]]\n",
      "0.8338945005611672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:    1.9s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:    2.6s remaining:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:    3.2s remaining:    3.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:    3.8s remaining:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:    4.5s remaining:    1.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOTING CLASSIFIER soft\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      alive       0.84      0.88      0.86       549\n",
      "       dead       0.80      0.73      0.76       342\n",
      "\n",
      "avg / total       0.82      0.82      0.82       891\n",
      "\n",
      "[[485  64]\n",
      " [ 92 250]]\n",
      "0.8249158249158249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:    5.6s finished\n"
     ]
    }
   ],
   "source": [
    "# Check performance of each classifier and see results of Voting\n",
    "k = 8\n",
    "# Set up classifiers, see if I can get something. I will derive some stuff later.\n",
    "for clf, label in zip(list, list_names):\n",
    "        # scores = cross_val_score(clf, x_tfidf, y, cv=8, scoring='accuracy', n_jobs=-1)\n",
    "        # print(\"Accuracy: %0.3f (+/- %0.3f) [%s]\" % (scores.mean(), scores.std(), label))\n",
    "    pred = cross_val_predict(\n",
    "            clf, train,\n",
    "            y=target,\n",
    "            cv=k, n_jobs=-1, verbose=20\n",
    "    )\n",
    "    print(label)\n",
    "    cm = confusion_matrix(target, pred)\n",
    "    print(cm)\n",
    "    accuracy = accuracy_score(target, pred)\n",
    "    print(accuracy)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[(i, j) for i, j in zip(list_names, list)], voting='hard')\n",
    "pred = cross_val_predict(\n",
    "            eclf, train, y=target, cv=k, n_jobs=-1, verbose=20\n",
    "        )\n",
    "print(\"VOTING CLASSIFIER hard\")\n",
    "cr = classification_report(target, pred, target_names=['alive','dead'])\n",
    "cm = confusion_matrix(target, pred)\n",
    "accuracy = accuracy_score(target, pred)\n",
    "# print(pred)\n",
    "print(cr)\n",
    "print(cm)\n",
    "print(accuracy)\n",
    "\n",
    "eclf = VotingClassifier(estimators=[(i, j) for i, j in zip(list_names, list)], voting='soft')\n",
    "pred = cross_val_predict(\n",
    "            eclf, train, y=target, cv=k, n_jobs=-1, verbose=20\n",
    "        )\n",
    "print(\"VOTING CLASSIFIER soft\")\n",
    "cr = classification_report(target, pred, target_names=['alive','dead'])\n",
    "cm = confusion_matrix(target, pred)\n",
    "accuracy = accuracy_score(target, pred)\n",
    "# print(pred)\n",
    "print(cr)\n",
    "print(cm)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('naive Gaussian', GaussianNB(priors=None)), ('logistic', LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='newton-cg', tol=0.0001,\n",
       "    ...timators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))],\n",
       "         flatten_transform=None, n_jobs=1, voting='hard', weights=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ultimately pick the HARD version of VotingClassifier\n",
    "list = [\n",
    "    clf14,\n",
    "    clf13,\n",
    "    clf8,\n",
    "]\n",
    "list_names = [\n",
    "    'naive Gaussian',\n",
    "    'logistic',\n",
    "    'ExtraTrees',\n",
    "]\n",
    "my_classifier = VotingClassifier(estimators=[(i, j) for i, j in zip(list_names, list)], voting='hard')\n",
    "my_classifier.fit(train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for test - first clean up :)\n",
    "test.drop('Cabin',axis=1,inplace=True)\n",
    "# As fare/pclass is strongly correlated, I will drop fare\n",
    "test.drop('Fare',axis=1,inplace=True)\n",
    "# I will drop ticket as well, it doesn't seem to mean anything\n",
    "test.drop('Ticket',axis=1,inplace=True)\n",
    "# Drop passengerid, completely useless\n",
    "test.drop('PassengerId',axis=1,inplace=True)\n",
    "# Apply helper functions to Emabarked, Sex\n",
    "test['Embarked'] = test['Embarked'].apply(impute_emb)\n",
    "test['Sex'] = test['Sex'].apply(impute_sex)\n",
    "# Impute Age\n",
    "test['Age'] = test[['Age','Pclass','SibSp']].apply(impute_age,axis=1)\n",
    "# Convert into age categories\n",
    "test['Age'] = pd.cut(test['Age'], bins=[0,17,64,100],labels=[1,2,3])\n",
    "test['Title'] = test['Name'].apply(get_title)\n",
    "\n",
    "test['Title'] = test['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Other')\n",
    "test['Title'] = test['Title'].replace('Mlle', 'Miss')\n",
    "test['Title'] = test['Title'].replace('Ms', 'Miss')\n",
    "test['Title'] = test['Title'].replace('Mme', 'Mrs')\n",
    "\n",
    "# Mapping\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "test['Title'] = test['Title'].map(title_mapping)\n",
    "test['Title'] = test['Title'].fillna(0)\n",
    "\n",
    "# Drop Name column\n",
    "test.drop('Name',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9425837320574163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "my_pred = my_classifier.predict(test)\n",
    "# Check score\n",
    "sub = pd.read_csv('gender_submission.csv')\n",
    "print(accuracy_score(my_pred,sub['Survived']))\n",
    "# This is currently tied for 22nd in Kaggle leaderboard :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
